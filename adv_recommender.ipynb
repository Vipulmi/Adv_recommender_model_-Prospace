{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "K9Ts0s7yCy96"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3gti_kO9dWn",
        "outputId": "79b96021-493a-4273-fea4-cbc78c0c7e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit-surprise-1.1.3.tar.gz (771 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.0/772.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-linux_x86_64.whl size=3162993 sha256=1db32c75e08cd4177ed6e940b09776b43bb7522efdb68a78b0367f88f84eba6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/ca/a8/4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.3 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Rtd0_fqk9dWo"
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries with the csv files for movies and ratings\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import Reader, Dataset, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "movies_data = pd.read_csv(\"movies.csv\")\n",
        "ratings_data = pd.read_csv(\"ratings.csv\")\n",
        "\n",
        "# User_id for model testing\n",
        "user_id = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-Tjr6H69dWo",
        "outputId": "943b120a-d883-45ca-c883-a2eb3d7c4f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Defining a custom tokenizer such genre entries like Sci-fi and (no genres listed) could be classified as a whole\n",
        "\n",
        "def custom_tokenizer(text):\n",
        "        pattern = r'[|]+'  # Split on | only\n",
        "        tokens = re.split(pattern, text)\n",
        "        return tokens\n",
        "\n",
        "vector = TfidfVectorizer(tokenizer=custom_tokenizer)\n",
        "x = vector.fit_transform(movies_data[\"genres\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV1Zmdii9dWp",
        "outputId": "1c9db393-7212-44e4-a664-91e64350ff4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended movies for John Wick (2014): \n",
            "\n",
            "1. Osterman Weekend, The (1983)\n",
            "2. The Forgotten (1989)\n",
            "3. The Last Survivors (2014)\n",
            "4. The Operative (2001)\n",
            "5. Paintball (2009)\n",
            "6. Darc (2018)\n",
            "7. Panic (2001)\n",
            "8. Hunting Emma (2017)\n",
            "9. Skyjacked (1972)\n",
            "10. Spirit (2012)\n"
          ]
        }
      ],
      "source": [
        "# Task 1\n",
        "\n",
        "def recommend_movies(movie_title, data, tfidf_matrix):\n",
        "\n",
        "    idx = data[data['title'] == movie_title].index[0]\n",
        "\n",
        "    sim_scores = cosine_similarity(tfidf_matrix[idx], tfidf_matrix).flatten()\n",
        "    sim_scores_idx = sim_scores.argsort()[::-1][1:11]  # Excluding the first movie (itself)\n",
        "\n",
        "    # Get titles of recommended movies\n",
        "    recommendations = data.iloc[sim_scores_idx]['title']\n",
        "\n",
        "    return recommendations.values\n",
        "\n",
        "# Example usage:\n",
        "movie_title = \"John Wick (2014)\"\n",
        "recommendations = recommend_movies(movie_title, movies_data, x)\n",
        "print(\"Recommended movies for {}: \\n\".format(movie_title))\n",
        "for i, movie in enumerate(recommendations, 1):\n",
        "    print(\"{}. {}\".format(i, movie))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dsDC9dm9dWp",
        "outputId": "d0deb09e-f610-4b7e-82ec-2d28ee7de4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content-Based Recommendations for User 128\n",
            "1. The Most Assassinated Woman in the World (2018)\n",
            "2. Inferno (2016)\n",
            "3. Grand Piano (2013)\n",
            "4. Cat o' Nine Tails, The (Gatto a nove code, Il) (1971)\n",
            "5. 23 Paces to Baker Street (1956)\n",
            "6. Fate (2008)\n",
            "7. 8 Remains (2018)\n",
            "8. Shattered (1991)\n",
            "9. Venetian Bird (1953)\n",
            "10. The Devil with Seven Faces (1971)\n"
          ]
        }
      ],
      "source": [
        "# Task 2\n",
        "\n",
        "# Content based recommendation\n",
        "def content_based(user_preferences, data, tfidf_matrix, vectorizer, n=10):\n",
        "    # Calculating cosine similarity between user preferences and all movies\n",
        "    user_preferences_vector = vectorizer.transform(user_preferences)\n",
        "    sim_scores = cosine_similarity(user_preferences_vector, tfidf_matrix)\n",
        "\n",
        "    # Sorting out the indices of movies with highest similarity scores\n",
        "    sim_scores_idx = sim_scores.argsort()[0][::-1][:n]\n",
        "\n",
        "    # Get titles of recommended movies\n",
        "    recommendations = data.iloc[sim_scores_idx]['title']\n",
        "\n",
        "    return recommendations.values\n",
        "\n",
        "user_preferences = movies_data[movies_data['movieId'].isin(ratings_data[ratings_data['userId'] == user_id]['movieId'])]['genres']\n",
        "cbr = content_based(user_preferences, movies_data, x, vector, n=10)\n",
        "\n",
        "print(\"Content-Based Recommendations for User\", user_id)\n",
        "for i, movie in enumerate(cbr, 1):\n",
        "    print(\"{}. {}\".format(i, movie))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvwChClu9dWp",
        "outputId": "ff09417d-9d14-4699-8b7c-e312d867b27e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7ba8f754ae00>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Collaborative filtering based on user-item relation\n",
        "\n",
        "# Making the dataset readable by the surprise lib and splitting it into training and testing dat\n",
        "reader = Reader(rating_scale=(0.5, 5))\n",
        "dat = Dataset.load_from_df(ratings_data[['userId', 'movieId', 'rating']], reader)\n",
        "trainset, testset = train_test_split(dat, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the model\n",
        "algo = SVD()\n",
        "algo.fit(trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YOmee8v9dWq",
        "outputId": "8adb5e50-6c79-4e27-c261-6c9d7f22ede6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collaborative Filtering Recommendations for User 128\n",
            "1. Whiplash (2014)\n",
            "2. Dark Knight Rises, The (2012)\n",
            "3. Bohemian Rhapsody (2018)\n",
            "4. Doctor Strange (2016)\n",
            "5. Rogue One: A Star Wars Story (2016)\n",
            "6. Iron Man 2 (2010)\n"
          ]
        }
      ],
      "source": [
        "# Testing the model\n",
        "# Accessing the predictions\n",
        "collab_preds = algo.test(testset)\n",
        "\n",
        "def get_top_n(predictions, n=10, userId=None):\n",
        "    # First map the predictions to each user\n",
        "    top_n = {}\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        if uid == userId:\n",
        "            if uid not in top_n:\n",
        "                top_n[uid] = []\n",
        "            top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve top N\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "# Showcasing the results\n",
        "i = 0\n",
        "top_n_collaborative = get_top_n(collab_preds, n=10, userId=user_id)\n",
        "print(\"\\nCollaborative Filtering Recommendations for User\", user_id)\n",
        "for movie_id, estimated_rating in top_n_collaborative[user_id]:\n",
        "    i += 1\n",
        "    movie_title = movies_data[movies_data['movieId'] == movie_id]['title'].iloc[0]\n",
        "    print(\"{}. {}\".format(i,movie_title, \"- Estimated Rating:\", round(estimated_rating, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3, Accuracy metrics for the collaborative filtering based approach\n",
        "\n",
        "from surprise import accuracy\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def evaluate_collaborative_filtering(predictions):\n",
        "    rmse = accuracy.rmse(predictions)\n",
        "    mae = accuracy.mae(predictions)\n",
        "    return rmse, mae\n",
        "\n",
        "evaluate_collaborative_filtering(collab_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bLt8VMAFc7b",
        "outputId": "1f3a13d5-b3d3-482a-aff3-2a182fe2c5df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8308\n",
            "MAE:  0.6320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8307598829983691, 0.6320388716132164)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Here, what I thought of doing was to find all the recommendations based on the movie John Wick\n",
        "# using all the methods developed."
      ],
      "metadata": {
        "id": "GJVS0TkNbtXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}